{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35ba699",
   "metadata": {},
   "source": [
    "# Transforms \n",
    "Data does not always come in its final processed form that is required for training machine learning algorithms. Transforms are used to perform some manipulation of the data and make it suitable for training \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2feab92",
   "metadata": {},
   "source": [
    "All TorchVision datasets have two parameters -transform to modify the features and target trainsform to modify the labels that accept callables containing the trainsfomation logic. The torchvision.transforms module offers several commonly used transforms out of the box "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ee7af",
   "metadata": {},
   "source": [
    "The FashionMNIST features are in PIL image format, and the labels are integers. For training we need to fatures as normalized ensors, and the labels as one hot encoded tensor. To make these transforms we use ToTensor and Lambda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016d0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets \n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "root = 'data',\n",
    "train = True,\n",
    "download = True,\n",
    "transform=ToTensor(),\n",
    "target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0,torch.tensor(y),value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce60042",
   "metadata": {},
   "source": [
    "## ToTensor()\n",
    "ToTensor converts a PIL image or NumPy array into a float tensor. and scales the images pixel intensity values in the range [0,1]\n",
    "\n",
    "## Lambda Transforms\n",
    "Lambda transforms apply any user defined lambda function. Here we define a function to turn the integer into a one hot encoded tensor. It first creates a zero tensor of size 10 on the index as given by the label y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ec2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_transform = Lambda(lambda y: torch.zeros(10,dtype=torch.float).scatter_(dim=0,index=torch.tensor(y),value=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890901e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
